<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://abhimanyu08.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://abhimanyu08.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-03-23T02:11:30-05:00</updated><id>https://abhimanyu08.github.io/blog/feed.xml</id><title type="html">Abhimanyu</title><subtitle>A blog where I write about things I learn on my self-taught journey in the field of Artificial Intelligence</subtitle><entry><title type="html">Bayesâ€™ Theorem</title><link href="https://abhimanyu08.github.io/blog/probability-theory/2020/03/23/final.html" rel="alternate" type="text/html" title="Bayes' Theorem" /><published>2020-03-23T00:00:00-05:00</published><updated>2020-03-23T00:00:00-05:00</updated><id>https://abhimanyu08.github.io/blog/probability-theory/2020/03/23/final</id><content type="html" xml:base="https://abhimanyu08.github.io/blog/probability-theory/2020/03/23/final.html">&lt;!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-03-23-final.ipynb
--&gt;

&lt;div class=&quot;container&quot; id=&quot;notebook-container&quot;&gt;
        
    
    
&lt;div class=&quot;cell border-box-sizing code_cell rendered&quot;&gt;

&lt;/div&gt;
    

&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;1.-Pre-requisites&quot;&gt;1. Pre-requisites&lt;a class=&quot;anchor-link&quot; href=&quot;#1.-Pre-requisites&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;You need to have knowledge of basic probability theory. If you are comfortable in calculating probabilities of discrete events and comfortable with the sum rule and product rule then you're good to go (If you're not, don't worry, I've tried to give a terse explaination using an example below). Try out this question.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Que&lt;/strong&gt; - Bag A has 5 red and 3 blue balls, Bag B has 6 red and 4 blue balls. The probability that a person chooses Bag A is 0.3 and he'll choose Bag B with probability 0.7. What is the probability of a person selecting a blue ball from bag B? What is the total probability of him coming out of with a red ball?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Ans&lt;/strong&gt; -&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Probability of choosing blue ball from B = (Probability of choosing B).(Probability of him picking blue ball &lt;strong&gt;given that&lt;/strong&gt; he selected B)&lt;/em&gt;. If your answer is 0.28, then you're comfortable enough with the product rule!!&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;em&gt;Probability of him coming out with a red ball = (Prob. of choosing red ball from A) + (Prob. of choosing red ball from B).&lt;/em&gt;(Notice that you can calculate entities inside bracket using the formula in first bullet point).If your answer comes out to be 0.6075, then you're comfortable enough with the sum rule to go through this blog post !!&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;Intuitively, sum rule comes in play when there is a choice between independent events (these events are generally seperated by a &lt;strong&gt;or&lt;/strong&gt; between them) for eg. The event of either choosing A and then a red ball &lt;strong&gt;or&lt;/strong&gt; B and then a red ball (as shown in 2. above).Product rule comes into play when two dependent events occur consecutively for eg. choosing bag B &lt;strong&gt;and&lt;/strong&gt; then selecting a blue ball from it (as shown in 1. above).&lt;/em&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;2.-Notations&quot;&gt;2. Notations&lt;a class=&quot;anchor-link&quot; href=&quot;#2.-Notations&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;P(X)&lt;/strong&gt; = Probality of event X. for eg. in above question P(A) = 0.3 where A = Event of person selecting bag A&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;P(X|Y)&lt;/strong&gt; = Probability of X given that Y has occured. for eg. in above question Probability of him picking blue ball given that he selected bag B = P(blue|B)&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;3.-Formula-and-basic-jargon&quot;&gt;3. Formula and basic jargon&lt;a class=&quot;anchor-link&quot; href=&quot;#3.-Formula-and-basic-jargon&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;Let me spit out the formula for Bayes' theorem quickly. Subsequently, I'll explain every term of the formula in detail using an example and introduce some basic jargon along the way.
&lt;img src=&quot;https://wikimedia.org/api/rest_v1/media/math/render/svg/87c061fe1c7430a5201eef3fa50f9d00eac78810&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;p&gt;Let's try to understand this formula using a familiar question involving bag A and bag B.&lt;/p&gt;
&lt;p&gt;All the details of the question are same as before. But now we are told that after everything has occured, the person was found having a blue ball in his hand. What are the odds that he selected that ball from Bag A? (Notice the sequence of events. It's easy to calculate probability of choosing a blue ball once the person has selected Bag A, because these two events have a cause and effect relationship. Choosing Bag A 'caused' the effect of selection of blue ball. But in the problem stated above, we're already given the 'effect' and are asked the 'cause' that caused it.)&lt;/p&gt;
&lt;p&gt;Let us define some symbols first,
P(A) = probability of selecting bag A which is given as 0.3 in the question.
P(B) = probability of selecting bag B which is given as 0.7 in the question.
P(b) = probability of selecting the blue ball.
P(r) = probability of selecting the red ball.&lt;/p&gt;
&lt;p&gt;We have to compute probability of having selected bag A &lt;strong&gt;given that&lt;/strong&gt; blue ball was found in person's hand i.e P(A|b).
Expanding this term using the formula gives us:
                                    &lt;strong&gt;P(A|b) = P(b|A).P(A)/ P(b)&lt;/strong&gt;    (3.1)&lt;/p&gt;
&lt;p&gt;The sentence &quot;The person was found having a blue ball in his hand&quot; is called &lt;strong&gt;Evidence&lt;/strong&gt;.In above expansion &lt;strong&gt;Evidence&lt;/strong&gt; is written mathematically as P(b) which is the denominator of our Eq.3.1.
To solve the question, we begin by listing all the ways through which &lt;strong&gt;Evidence&lt;/strong&gt; could have occured. There are two ways in which blue ball could have landed in person's hand:-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;He selected A &lt;strong&gt;and&lt;/strong&gt; then picked up a blue ball &lt;strong&gt;or&lt;/strong&gt; 2. He selected B &lt;strong&gt;and&lt;/strong&gt; then picked up a blue ball.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;All these listed ways make up our P(b) in Eq.3.1. Thus P(b) written mathematically will be equal to 
                                         &lt;strong&gt;P(A).P(b|A) + P(B).P(b|B)&lt;/strong&gt;  (3.2)&lt;/p&gt;
&lt;p&gt;With the help of new parlance, let's convert our question into a hypothesis. Given the &lt;strong&gt;Evidence&lt;/strong&gt;, that blue ball was found in person's hand, let's say we &lt;em&gt;hypothesise&lt;/em&gt; that ball must have come from Bag A. Now, we go ahead and test whether our hypothesis holds true.&lt;/p&gt;
&lt;p&gt;Now, I want you to make a intuitive guess about the answer of our question (or correctness of our hypothesis) .What do you think are the odds that Bag A was selected by the person carrying the blue ball? One could argue that the odds are 0.3 or P(A), because if we say to a new person to select a bag, he would choose A with probability 0.3. Thus, odds are that previous person (the one carrying the blue ball) also would have selected A with probability 0.3. Thus P(A) here is called &lt;strong&gt;Prior&lt;/strong&gt;, because it reflects our &lt;em&gt;prior belief&lt;/em&gt; about the selection of A &lt;em&gt;before seeing the&lt;/em&gt; &lt;strong&gt;Evidence&lt;/strong&gt;.
Now, what are the chances that he selects blue ball given that he selected bag A, in other words what are the chances of seeing the &lt;strong&gt;Evidence&lt;/strong&gt; given that our &lt;strong&gt;Hypothesis&lt;/strong&gt; is true? Mathematically speaking, P(b|A). This entity is called &lt;strong&gt;Likelihood&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Likelihood&lt;/strong&gt; and &lt;strong&gt;Prior&lt;/strong&gt; make up the numerator in the formula of Bayes' theorem. Thus our numerator is 
                                                &lt;strong&gt;P(b|A).P(A)&lt;/strong&gt;. (3.3)&lt;/p&gt;
&lt;p&gt;Intuitively, we can think of it as following:-
Out of all the cases that make up our evidence (P(b)) we are only interested in the ones in which our hypothesis holds true. Thus only the case no 1 from above list of cases interests us and we put that in our numerator. And if you remember, that is basic probability; we calculate probability using the formula &lt;strong&gt;cases that interest us/ total no of cases&lt;/strong&gt;. for eg what are the odds of selecting a red card from a deck of cards -&amp;gt; 26/52 or 0.5.&lt;/p&gt;
&lt;p&gt;Thus,finally after putting all the pieces together we can calculate 
&lt;strong&gt;P(A|b) = P(b|A).P(A)/ P(b)&lt;/strong&gt; = &lt;strong&gt;P(A).P(b|A) / (P(A).P(b|A) + P(B).P(b|B)&lt;/strong&gt;) = 0.2866&lt;/p&gt;
&lt;p&gt;The calculated probability &lt;strong&gt;P(A|b)&lt;/strong&gt; is called the &lt;strong&gt;Posterior&lt;/strong&gt;. This probability is an updated version of our &lt;strong&gt;Prior&lt;/strong&gt;
based on new evidence.Now that we found the evidence that person was holding blue ball, we believe that he must have chosen bag A with probability 0.28(&lt;strong&gt;posterior&lt;/strong&gt;) instead of 0.3(&lt;strong&gt;prior&lt;/strong&gt;). Notice that probability goes down and intuitively this makes sense because Bag B has more blue balls than A, so if a person is found having the blue ball it's likely that it came from B. This is the main motive of Bayes' theorem. It helps us update our &lt;strong&gt;Prior&lt;/strong&gt; beliefs continuously by collecting new &lt;strong&gt;Evidence&lt;/strong&gt;.&lt;/p&gt;
&lt;h4 id=&quot;Quick-summary-and-technique-to-solve-problems-involving-Bayes'-Theorem-:&quot;&gt;Quick summary and technique to solve problems involving Bayes' Theorem :&lt;a class=&quot;anchor-link&quot; href=&quot;#Quick-summary-and-technique-to-solve-problems-involving-Bayes'-Theorem-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Find out what is &lt;strong&gt;given&lt;/strong&gt; in the problem. The given part serves as &lt;strong&gt;Evidence&lt;/strong&gt; which aids us in assessing our &lt;strong&gt;Hypothesis&lt;/strong&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;List out all the ways in which &lt;strong&gt;Evidence&lt;/strong&gt; could have occured, calculate the probabilities of those ways using product rule and sum rule and write them as denominator.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Pick out the way amongst the list of ways in which your &lt;strong&gt;Hypothesis&lt;/strong&gt; holds true and put the probability of that way in the numerator.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;4.-Interesting-Study-Demonstrating-The-Counter-Intutiveness-Of-The-Bayes'-Theorem&quot;&gt;4. Interesting Study Demonstrating The Counter-Intutiveness Of The Bayes' Theorem&lt;a class=&quot;anchor-link&quot; href=&quot;#4.-Interesting-Study-Demonstrating-The-Counter-Intutiveness-Of-The-Bayes'-Theorem&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;em&gt;(This part of blog is inspired from a great video by &lt;a href=&quot;https://youtu.be/HZGCoVF3YvM&quot;&gt;3 Blue 1 Brown&lt;/a&gt;).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Let me ask you an interesting question.
&lt;strong&gt;Steve is very shy and withdrawn, invariably helpful but with little interest in people or in the world of reality. A meek and tidy soul, he has a need for order and structure, and a passion for detail.&quot;&lt;/strong&gt; Having read this sentence what do you think is the profession of Steve, a &lt;em&gt;librarian&lt;/em&gt; or a &lt;em&gt;farmer&lt;/em&gt; ?&lt;/p&gt;
&lt;p&gt;(&lt;em&gt;This quesion was asked by Nobel Laureate &lt;a href=&quot;https://en.wikipedia.org/wiki/Daniel_Kahneman&quot;&gt;Daniel Kahneman&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Amos_Tversky&quot;&gt;Amos Tversky&lt;/a&gt; in the studies which they conducted that showed that humans are intuitively bad staticians (even those who had PhDs in the field of statistics) and sometimes overestimate the correctness of their prior beliefs. Daniel Kahneman has written about these studies in his book &quot;Thinking ,fast and slow&quot;.&lt;/em&gt;)&lt;/p&gt;
&lt;p&gt;Most people would guess that Steve is a librarian because he fits in the stereotypical image of one. Let's look at this problem with a Bayesian perspective. Let's say that the sentence written in bold above is our &lt;strong&gt;Evidence&lt;/strong&gt;. Now we &lt;strong&gt;Hypothesise&lt;/strong&gt; that &lt;em&gt;Steve is a librarian&lt;/em&gt;. Let's calculate the validity of our hypothesis.&lt;/p&gt;
&lt;p&gt;Steve is a random person taken from a representative sample. Let's say the probability of observing the above traits in a random person are P(E).
Let the probability of a random person being a farmer be P(F).
Let the probability of a random person being a librarian be P(L)&lt;/p&gt;
&lt;p&gt;We would have to consider following questions to calculate the probability of our hypothesis given the evidence:-&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Out of 100 librarians how many do you think fit the description given above in bold typeface? We are allowed to incorporate our stereotypes in estimating the answer to this question. Let's say 85 librarians fit the evidence. Mathematically speaking, &lt;strong&gt;given that&lt;/strong&gt; a person is a librarian, the probability of him fiiting the above evidence (he is shy and a &quot;meek and tidy soul&quot;) is  P(E|L) = 0.85&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Out of 100 farmers how many do you think fit the description given above in bold typeface? Let's say 30 farmers fit the evidence.(Beacuse we all stereotypically think that farmers are less likely to be shy or a &quot;meek and tidy soul&quot;).Mathematically speaking, &lt;strong&gt;given that&lt;/strong&gt; a person is a farmer, the probability of him fiiting the above evidence is  P(E|F) = 0.3&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;We also need to take into account some statistical facts to decide our prior beliefs. At the time of conduction of this study, there were 20 farmers for every 1 librarian in america. Thus, out of 210, 10 people are librarian and 200 are farmers.Therefore, probability of a random person being a farmer i.e P(F) = 0.95 and probability of a random person being a librarian i.e P(L) is 0.05 (assuming our representative sample has only farmers and librarians).&lt;/p&gt;
&lt;h4 id=&quot;Listing-all-the-ways-in-which-the-evidence-can-occur-:&quot;&gt;Listing all the ways in which the evidence can occur :&lt;a class=&quot;anchor-link&quot; href=&quot;#Listing-all-the-ways-in-which-the-evidence-can-occur-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;The person selected at random is a librarian &lt;strong&gt;and&lt;/strong&gt; he is a &quot;meek and tidy soul&quot; &lt;strong&gt;or&lt;/strong&gt; 2. The person selected at random is a farmer &lt;strong&gt;and&lt;/strong&gt; he is a &quot;meek and tidy soul&quot;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Writing this mathematically -&amp;gt; &lt;strong&gt;P(L).P(E|L) + P(F).P(E|F)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;The case which interests us is case 1. Thus, &lt;strong&gt;P(L|E) = P(L).P(E|L) / P(L).P(E|L) + P(F).P(E|F)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After doing the above calculation we find out that probability of Steve being a librarian is a mere 13 %. In other words only 13 out of 100 &quot;meek and tidy souls&quot; are librarians. This seems surprising and counter-intuitive because we incorporated our stereotypes in our calculations (by saying that 85 out of 100 librarians fit the evidence), yet the final calculations conclude that our hypothesis (which complied with our stereotypes) was wrong. 
An intutive way of thinking about this is as following:
There are way more farmers in general population than librarians, therfore there are way more &quot;meek and tidy souls&quot; ploughing the fields (77 out of 100 as per our calculations) than those who are meticulously keeping the books in the library. Take a sample of 210 people for example out of which 10 are librarians and 200 are farmers. According to our stereotypical estimates 85% of 10 librarians or ~9 librarians are shy, while only 30% of 200 lirarians or ~60 farmers are shy.Hence,out of 210 people 69 people are shy and tidy souls, majority of which are farmers. Thus if we randomly found a guy named Steve and he comes out as shy, he's probably a farmer.&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;h2 id=&quot;5.-Bayes'-Theorem-As-A-Way-Of-Updating-Our-Priors-And-Belief-Systems-.&quot;&gt;5. Bayes' Theorem As A Way Of Updating Our Priors And Belief Systems .&lt;a class=&quot;anchor-link&quot; href=&quot;#5.-Bayes'-Theorem-As-A-Way-Of-Updating-Our-Priors-And-Belief-Systems-.&quot;&gt; &lt;/a&gt;&lt;/h2&gt;&lt;p&gt;&lt;em&gt;(This part of blog is inspired from this great video by &lt;a href=&quot;https://youtu.be/R13BD8qKeTg&quot;&gt;Veritasium&lt;/a&gt;)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Suppose, you go to a doctor and he tells you that results of your test for a disease are unfortunately positive. It is known that 0.1% of the population might have the disease. You know that the tests you took give correct results 99% of the time. Thus, you may be disheartened because such an accurate test has declared you of being sick from a rare disease. Intuitively, you would think that there is a 99% chance of you having this disease. But, let's look at this from a bayesian perspective.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Evidence&lt;/strong&gt; -&amp;gt; The test shows positive. P(E) = 0.99
&lt;strong&gt;Hypothesis&lt;/strong&gt; -&amp;gt; You have the disease &lt;strong&gt;given&lt;/strong&gt; the evidence.
&lt;strong&gt;Prior belief before seeing the evidence&lt;/strong&gt; -&amp;gt; Probaility of your having the disease. P(D) = 0.001 (because 0.1% of the population has it and you're part of the population)&lt;/p&gt;
&lt;h4 id=&quot;Ways-In-Which-Evidence-Can-Be-Observed-(Test-results-Can-Come-Out-As-Positive).-:&quot;&gt;Ways In Which Evidence Can Be Observed (Test results Can Come Out As Positive). :&lt;a class=&quot;anchor-link&quot; href=&quot;#Ways-In-Which-Evidence-Can-Be-Observed-(Test-results-Can-Come-Out-As-Positive).-:&quot;&gt; &lt;/a&gt;&lt;/h4&gt;&lt;ol&gt;
&lt;li&gt;You have the disease &lt;strong&gt;and&lt;/strong&gt; test comes as positive. &lt;strong&gt;or&lt;/strong&gt; 2. You don't have the disease &lt;strong&gt;and&lt;/strong&gt; test shows positive (incorrectly).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Mathematically -&amp;gt; &lt;strong&gt;P(D).P(E|D) + P(-D).P(E|-D)&lt;/strong&gt;   {P(-D) -&amp;gt; Probability of not having the disease}.&lt;/p&gt;
&lt;p&gt;We are interested in case 1.&lt;/p&gt;
&lt;p&gt;Thus, probability of you having the disease &lt;strong&gt;given&lt;/strong&gt; positive test results = &lt;strong&gt;P(D).P(E|D) / P(D).P(E|D) + P(~D).P(E|~D)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;After calculations, the probability of you having the disease comes out to be a mere 9%, which again seems counter-intuitive. Even after being declared positive by a pretty accurate test you are probably healthy and test is False! &lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;This counter-intuitiveness stems from the fact that probability of our &lt;strong&gt;hypothesis given the evidence&lt;/strong&gt; depends heavily on our &lt;strong&gt;prior&lt;/strong&gt; i.e probability of our hypothesis being correct without the evidence (P(D) in above calculation). In this particular example, the probability of us having the disease without having the test results in our hand was so low (0.001) that even the new strong evidence couldn't vote in favour of our hypothesis that we have the disease.&lt;/p&gt;
&lt;p&gt;Think of just 1000 people which also includes you. According to given data, 1 out these 1000 is sick from the disease. Let's say that he goes for the test and is correctly identified as positive. Let's say the other 999 also go for tests. The test will falsely identify 1% of 999 healthy people, i.e 10 healthy people are shown positive. So now, there are 11 people in entire population with positive test results and you are one of them. Out of these 11 positive test results only 1 is correct. That's why having a positive result is not as bad as you might think !!&lt;/p&gt;
&lt;h3 id=&quot;But-What-If-You-Took-A-Second-Test-And-It-Comes-As-Positive-:&quot;&gt;But What If You Took A Second Test And It Comes As Positive :&lt;a class=&quot;anchor-link&quot; href=&quot;#But-What-If-You-Took-A-Second-Test-And-It-Comes-As-Positive-:&quot;&gt; &lt;/a&gt;&lt;/h3&gt;&lt;p&gt;Suppose just to be sure, you go through tests from a different lab and that result also comes out as positive (assuming that that lab also gives correct results 99% of the times). Now, what are the chances that you have the disease.Everything remains the same in terms of data except the &lt;strong&gt;prior&lt;/strong&gt;. The basic definition of the prior is &lt;strong&gt;&quot;Probability that your hypothesis is true without the evidence&quot;&lt;/strong&gt;. Thus, in this case the &lt;strong&gt;prior&lt;/strong&gt; is probability of you having the disease without having seen the results from second test. Therefore, prior comes out to be 9% or 0.09 for the second case (&lt;strong&gt;Posterior&lt;/strong&gt; from the first test). Even though the earlier tests were likely to be false, they served us by updating our &lt;strong&gt;prior&lt;/strong&gt; from 0.001 to 0.09 by providing us with a strong evidence.&lt;/p&gt;
&lt;p&gt;The probability of having the disease &lt;strong&gt;given&lt;/strong&gt; that second test result is also positive = 0.99*0.09/(0.99*0.09 + 0.01*0.91) = 91 %. 
&lt;strong&gt;Thus, now you have 91% chances of being sick and intuitively this makes sense because the chances of two such accurate tests showing false results are pretty low.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;This case shows that Bayes' theorem serves us by updating our priors with help of new evidences. The posteriors serve as priors for the next time any evidence is collected. This process iteratively helps in scientifically solidifying or falsifying our hypotheses by regularly collecting new evidences and updating our Priors subsequently.&lt;/strong&gt;&lt;/p&gt;

&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;cell border-box-sizing text_cell rendered&quot;&gt;&lt;div class=&quot;inner_cell&quot;&gt;
&lt;div class=&quot;text_cell_render border-box-sizing rendered_html&quot;&gt;
&lt;script src=&quot;https://utteranc.es/client.js&quot; repo=&quot;Abhimanyu08/blog&quot; issue-term=&quot;pathname&quot; theme=&quot;github-light&quot; crossorigin=&quot;anonymous&quot; async=&quot;&quot;&gt;
&lt;/script&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><author><name></name></author><summary type="html"></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://abhimanyu08.github.io/blog/images/1.jpg" /><media:content medium="image" url="https://abhimanyu08.github.io/blog/images/1.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry></feed>